#:schema https://api.nuon.co/v1/general/config-schema?source=action

name    = "simulate_db_activity"
timeout = "30m"

[[triggers]]
type = "manual"

[[steps]]
name    = "create sample data and run fluctuating load"
inline_contents = """
#!/usr/bin/env sh

echo "Starting INTENSIVE database activity simulation..."

# Check if PostgreSQL is ready
echo "Checking if PostgreSQL is ready..."
if kubectl get pod postgresql-0 -n exampledb >/dev/null 2>&1; then
    echo "PostgreSQL pod found, proceeding..."
else
    echo "PostgreSQL pod not found, exiting..."
    exit 1
fi

# Create comprehensive schema and large seed data (idempotent)
kubectl exec -n exampledb postgresql-0 -- env PGPASSWORD="$EXAMPLEDB_PASSWORD" psql -U exampledb -d exampledb -c "
-- Create comprehensive schema (safe for repeated runs)
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(100) UNIQUE,
    age INTEGER,
    city VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS products (
    id SERIAL PRIMARY KEY,
    name VARCHAR(200),
    category VARCHAR(50),
    price DECIMAL(10,2),
    stock INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    product_id INTEGER REFERENCES products(id),
    quantity INTEGER,
    amount DECIMAL(10,2),
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS sessions (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    session_token VARCHAR(100),
    ip_address INET,
    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS audit_log (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(50),
    action VARCHAR(20),
    old_data JSONB,
    new_data JSONB,
    user_id INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for performance testing (safe for repeated runs)
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_orders_user_id ON orders(user_id);
CREATE INDEX IF NOT EXISTS idx_orders_created_at ON orders(created_at);
CREATE INDEX IF NOT EXISTS idx_sessions_user_id ON sessions(user_id);
CREATE INDEX IF NOT EXISTS idx_audit_created_at ON audit_log(created_at);

-- Insert substantial seed data (10K users, 5K products)
INSERT INTO users (name, email, age, city) 
SELECT 
    'User' || generate_series(1,10000),
    'user' || generate_series(1,10000) || '@example.com',
    (random() * 60 + 18)::int,
    (ARRAY['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose'])[floor(random() * 10 + 1)]
ON CONFLICT (email) DO NOTHING;

INSERT INTO products (name, category, price, stock)
SELECT 
    'Product ' || generate_series(1,5000),
    (ARRAY['Electronics', 'Clothing', 'Books', 'Home', 'Sports', 'Beauty', 'Automotive', 'Food'])[floor(random() * 8 + 1)],
    round((random() * 1000 + 10)::numeric, 2),
    floor(random() * 1000)::int;

-- Insert historical orders (50K records)
INSERT INTO orders (user_id, product_id, quantity, amount, status, created_at)
SELECT 
    floor(random() * 10000 + 1)::int,
    floor(random() * 5000 + 1)::int,
    floor(random() * 5 + 1)::int,
    round((random() * 500 + 10)::numeric, 2),
    (ARRAY['pending', 'completed', 'cancelled', 'refunded'])[floor(random() * 4 + 1)],
    NOW() - (random() * interval '30 days');
"

echo "Schema created. Starting fluctuating activity..."

# Create stop check function
check_stop_signal() {
    kubectl exec -n exampledb postgresql-0 -- test -f /tmp/stop_db_simulation 2>/dev/null && echo "STOP" || echo "CONTINUE"
}

# Function to run INTENSIVE burst of activity
run_activity_burst() {
    local intensity=$1
    echo "Running INTENSIVE burst with intensity: $intensity concurrent connections"
    
    # DASHBOARD-TARGETED queries to spin all gauges and meters
    for i in $(seq 1 $intensity); do
        kubectl exec -n exampledb postgresql-0 -- env PGPASSWORD="$EXAMPLEDB_PASSWORD" psql -U exampledb -d exampledb -c "
        -- ROWS OPERATIONS (fetched, returned, inserted, updated, deleted per second)
        -- Massive row fetches for 'rows fetched' gauge
        SELECT * FROM users ORDER BY id LIMIT 5000;
        SELECT * FROM products WHERE stock > 0 ORDER BY price DESC LIMIT 3000;
        SELECT * FROM orders WHERE created_at >= NOW() - interval '7 days' LIMIT 8000;
        
        -- Complex JOINs for 'rows returned' gauge  
        SELECT u.*, o.*, p.* FROM users u 
        JOIN orders o ON u.id = o.user_id 
        JOIN products p ON o.product_id = p.id 
        WHERE o.created_at >= NOW() - interval '1 day'
        LIMIT 2000;
        
        -- INSERTS for 'rows inserted' gauge
        INSERT INTO sessions (user_id, session_token, ip_address, last_activity) 
        SELECT 
            floor(random() * 10000 + 1)::int,
            md5(random()::text || i::text),
            ('10.0.' || floor(random() * 255) || '.' || floor(random() * 255))::inet,
            NOW() - (random() * interval '1 hour')
        FROM generate_series(1, 100);
        
        INSERT INTO orders (user_id, product_id, quantity, amount, status) 
        SELECT 
            floor(random() * 10000 + 1)::int,
            floor(random() * 5000 + 1)::int,
            floor(random() * 10 + 1)::int,
            round((random() * 1000)::numeric, 2),
            (ARRAY['pending','processing','shipped'])[floor(random() * 3 + 1)]
        FROM generate_series(1, 75);
        
        -- UPDATES for 'rows updated' gauge
        UPDATE products SET stock = stock - floor(random() * 5)::int 
        WHERE id IN (SELECT id FROM products WHERE stock > 10 ORDER BY random() LIMIT 500);
        
        UPDATE users SET updated_at = NOW() 
        WHERE id IN (SELECT id FROM users ORDER BY random() LIMIT 300);
        
        UPDATE orders SET status = 'completed', amount = amount * 1.1 
        WHERE status = 'processing' AND random() < 0.4;
        
        -- DELETES for 'rows deleted' gauge
        DELETE FROM sessions WHERE last_activity < NOW() - interval '4 hours' AND random() < 0.3;
        DELETE FROM audit_log WHERE created_at < NOW() - interval '1 day' AND random() < 0.1;
        
        -- TRANSACTIONS and COMMITS/ROLLBACKS for QPS gauge
        BEGIN; 
        INSERT INTO audit_log (table_name, action, new_data) VALUES ('simulation', 'test_txn', '{\"test\": true}');
        IF random() > 0.1 THEN 
            COMMIT; 
        ELSE 
            ROLLBACK;
        END IF;
        
        -- DEADLOCK simulation (controlled)
        IF random() < 0.05 THEN
            BEGIN;
            UPDATE products SET stock = stock + 1 WHERE id = 1;
            SELECT pg_sleep(0.1);
            UPDATE users SET updated_at = NOW() WHERE id = 1; 
            COMMIT;
        END IF;
        
        -- CACHE HIT RATIO - access same data repeatedly
        SELECT COUNT(*) FROM users WHERE city = 'NYC';
        SELECT COUNT(*) FROM users WHERE city = 'NYC';
        SELECT COUNT(*) FROM users WHERE city = 'LA';
        SELECT COUNT(*) FROM users WHERE city = 'LA';
        
        -- BUFFER activity - large sequential scans
        SELECT COUNT(*) FROM orders WHERE amount > 100;
        SELECT AVG(amount) FROM orders WHERE created_at >= NOW() - interval '1 week';
        
        -- INDEX usage vs table scans
        SELECT * FROM orders WHERE user_id = floor(random() * 1000 + 1)::int; -- uses index
        SELECT * FROM orders WHERE amount = floor(random() * 100 + 50)::numeric(10,2); -- table scan
        " > /dev/null 2>&1 &
        
        # Minimal delay to create overlapping connections
        sleep 0.05
    done
    
    # Additional CONNECTION-HEAVY processes for 'Active Connections' gauge
    for j in $(seq 1 $((intensity/2))); do
        kubectl exec -n exampledb postgresql-0 -- env PGPASSWORD="$EXAMPLEDB_PASSWORD" psql -U exampledb -d exampledb -c "
        -- ACTIVE CONNECTIONS - long-running queries to show in pg_stat_activity
        SELECT pg_sleep(random() * 3 + 1); -- Hold connection open 1-4 seconds
        
        -- LOCK CONTENTION for locks/conflicts metrics
        SELECT COUNT(*) FROM orders o1 JOIN orders o2 ON o1.user_id = o2.user_id 
        WHERE o1.id != o2.id AND o1.created_at >= NOW() - interval '1 week';
        
        -- SEQUENTIAL SCANS for buffer hit ratio impact
        SELECT * FROM users WHERE age > 50 ORDER BY created_at DESC LIMIT 1000; -- no index on age
        SELECT * FROM products WHERE category LIKE '%Electronics%' ORDER BY price; 
        
        -- CONNECTION POOL simulation - quick connects/disconnects
        SELECT current_database(), current_user, inet_server_addr(), inet_server_port();
        SELECT version(), current_setting('max_connections');
        " > /dev/null 2>&1 &
        sleep 0.02
    done
    
    echo "Burst initiated with $intensity + $((intensity/2)) background processes"
}

# Create PID tracking file for proper cleanup
echo $$ > /tmp/db_simulation_main_pid

# Intensive simulation over 25 minutes with much higher loads
echo "Starting 25-minute INTENSIVE fluctuating load simulation..."
echo "This will create significant database load - monitor your dashboards!"

for cycle in $(seq 1 50); do
    # Check for stop signal
    if [ "$(check_stop_signal)" = "STOP" ]; then
        echo "Stop signal detected, ending simulation..."
        break
    fi
    
    echo "=== Cycle $cycle/50 ==="
    
    # Much higher intensity waves (low=20, medium=50, high=100 concurrent connections)
    case $((cycle % 8)) in
        0|1) intensity=20 ;;   # Low activity (still 4x original)
        2|3) intensity=50 ;;   # Medium activity  
        4|5) intensity=100 ;;  # High activity
        6) intensity=150 ;;    # Peak activity
        7) intensity=75 ;;     # Cooldown
    esac
    
    # Add random spikes
    if [ $((RANDOM % 10)) -eq 0 ]; then
        intensity=$((intensity + 50))
        echo "*** RANDOM SPIKE: intensity boosted to $intensity ***"
    fi
    
    run_activity_burst $intensity
    
    # Shorter rest periods for more sustained load (5-15 seconds)
    rest_time=$((5 + (cycle % 3) * 5))
    echo "Brief rest for ${rest_time}s before next burst..."
    sleep $rest_time
done

echo "Activity simulation completed!"
echo "Check your Grafana dashboard to see the fluctuating database metrics."
"""

[steps.env_vars]
EXAMPLEDB_PASSWORD = "exampledb"